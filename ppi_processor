import networkx as nx
import gzip
import pandas as pd
import numpy as np
from collections import deque

class PPI_processor:
    def __init__(self, file_path):
        try:
            # 检查文件扩展名
            if file_path.endswith('.gz'):
                # 如果是压缩文件，使用 gzip.open 打开
                with gzip.open(file_path, "rt") as file:
                    self._data = pd.read_csv(file, sep=' ', nrows=5000)
            else:
                # 如果是普通文件，直接打开
                self._data = pd.read_csv(file_path, sep=' ', nrows=5000)
        except FileNotFoundError:
            print(f"错误：文件 {file_path} 不存在。")
            self._data = None
        except pd.errors.EmptyDataError:
            print(f"错误：文件 {file_path} 是空的。")
            self._data = None
        except pd.errors.ParserError:
            print(f"错误：文件 {file_path} 无法解析。")
            self._data = None
        except Exception as e:
            print(f"未知错误：{e}")
            self._data = None

    def normalize_values(self, index='combined_score', min_value=None, max_value=None):
        """
        将输入值归一化到 (0, 1000) 区间。
        :param index: 需要归一化的列名，默认为 'combined_score'
        :param min_value: 如果已知最小值，可以直接传入，否则将从数据中计算
        :param max_value: 如果已知最大值，可以直接传入，否则将从数据中计算
        :return: 归一化后的值列表
        """
        if min_value is None:
            self._min_value = min(self._data[index])
        else:
            self._min_value = min_value
        if max_value is None:
            self._max_value = max(self._data[index])
        else:
            self._max_value = max_value

        if self._max_value == self._min_value:
            raise ValueError("最大值和最小值相同，无法进行归一化。")

        normalized_to_one = [(x - self._min_value) / (self._max_value - self._min_value) for x in self._data[index]]
        self._data['normalized_values'] = [(1000 - x * 1000) for x in normalized_to_one]

    def graph_builder(self, combined_score_index='combined_score', normalized_score_index='normalized_values'):
        """
        根据 PPI 数据构建无向图。
        :param combined_score_index: 存储原始 combined_score 的列名，默认为 'combined_score'
        :param normalized_score_index: 存储归一化分数的列名，默认为 'normalized_values'
        """
        if combined_score_index not in self._data.columns or normalized_score_index not in self._data.columns:
            raise ValueError(f"列 {combined_score_index} 或 {normalized_score_index} 不存在于数据中。")

        self._graph = nx.Graph()

        all_proteins = pd.concat([self._data['protein1'], self._data['protein2']]).unique()
        for protein in all_proteins:
            self._graph.add_node(protein)

        edges = self._data[['protein1', 'protein2', combined_score_index, normalized_score_index]].values
        for protein1, protein2, combined_score, normalized_score in edges:
            self._graph.add_edge(protein1, protein2, combined_score=combined_score, normalized_score=normalized_score)

    def get_local_subgraph(self, protein, k=3):
        """
        使用 BFS 获取目标蛋白质周围的 k 层蛋白质的子图。
        :param protein: 目标蛋白质
        :param k: 限制范围为蛋白质周围的 k 层，默认为 3
        :return: 返回目标蛋白质周围的 k 层蛋白质的无向图
        """
        if not hasattr(self, '_graph') or self._graph is None:
            print("错误：图尚未构建。请先调用 graph_builder 方法。")
            return None

        if protein not in self._graph:
            print(f"错误：蛋白质 {protein} 不在图中。")
            return None

        visited = set()
        queue = deque([(protein, 0)])  # (当前蛋白质, 当前层数)
        visited.add(protein)
        while queue:
            current_protein, current_layer = queue.popleft()
            if current_layer == k:
                break
            for neighbor in self._graph.neighbors(current_protein):
                if neighbor not in visited:
                    visited.add(neighbor)
                    queue.append((neighbor, current_layer + 1))

        local_graph = self._graph.subgraph(visited).copy()
        return local_graph

    def print_graph_info(self):
        """
        打印图的节点和边信息。
        """
        node_data = {
            "Node": list(self._graph.nodes()),
            "Degree": [self._graph.degree(node) for node in self._graph.nodes()]
        }
        node_df = pd.DataFrame(node_data)

        edge_data = {
            "Source": [edge[0] for edge in self._graph.edges()],
            "Target": [edge[1] for edge in self._graph.edges()],
            "Combined Score": [self._graph.edges[edge].get('combined_score', None) for edge in self._graph.edges()],
            "Normalized Score": [self._graph.edges[edge].get('normalized_score', None) for edge in self._graph.edges()]
        }
        edge_df = pd.DataFrame(edge_data)

        print("Node Information:")
        print(node_df)

        print("\nEdge Information:")
        print(edge_df)

    def query_protein_distance(self, protein1, protein2):
        """
        查询两个蛋白质之间的最短路径长度（距离）以及路径上的置信度。
        :param protein1: 第一个蛋白质的标识符
        :param protein2: 第二个蛋白质的标识符
        :return: 两个蛋白质之间的最短路径长度、路径和路径上的置信度
        """
        if self._graph is None:
            print("错误：图尚未构建。请先调用 graph_builder 方法。")
            return None

        if protein1 not in self._graph or protein2 not in self._graph:
            print(f"错误：蛋白质 {protein1} 或 {protein2} 不在图中。")
            return None

        try:
            path = nx.shortest_path(self._graph, source=protein1, target=protein2, weight='normalized_score')
            distance = nx.shortest_path_length(self._graph, source=protein1, target=protein2, weight='normalized_score', method="dijkstra")

            confidence = [self._graph[path[i]][path[i + 1]]['combined_score'] for i in range(len(path) - 1)]

            print(f"蛋白质 {protein1} 和 {protein2} 之间的最短路径长度为：{distance}")
            print(f"路径为：{path}")
            print(f"路径上的原始 combined_score 为：{confidence}")

            return distance, path, confidence
        except nx.NetworkXNoPath:
            print(f"蛋白质 {protein1} 和 {protein2} 之间不存在路径。")
            return None

    def find_nearest_proteins(self, protein, n=5, k=3):
        """
        找到指定蛋白质在图中最近的 n 个蛋白质。
        :param protein: 目标蛋白质的标识符
        :param n: 返回的最近邻居数量，默认为 5
        :param k: 限制搜索范围为目标蛋白质周围的 k 层，默认为 3
        :return: 最近的 n 个蛋白质及其距离、路径和置信度
        """
        if not hasattr(self, '_graph') or self._graph is None:
            print("错误：图尚未构建。请先调用 graph_builder 方法。")
            return None

        if protein not in self._graph:
            print(f"错误：蛋白质 {protein} 不在图中。")
            return None

        local_graph = self.get_local_subgraph(protein, k=k)
        if local_graph is None:
            return None

        shortest_paths = nx.single_source_dijkstra_path_length(local_graph, source=protein, weight='normalized_score')
        protein_distances = [(candidate, shortest_paths[candidate]) for candidate in local_graph.nodes() if candidate != protein]
        protein_distances.sort(key=lambda x: x[1])
        nearest_proteins = protein_distances[:n]

        nearest_proteins_with_distance_and_path = []
        for protein2, distance in nearest_proteins:
            try:
                path = nx.shortest_path(local_graph, source=protein, target=protein2, weight='normalized_score')
                confidence = [local_graph[path[i]][path[i + 1]]['combined_score'] for i in range(len(path) - 1)]
                nearest_proteins_with_distance_and_path.append((protein2, distance, path, confidence))
            except nx.NetworkXNoPath:
                print(f"警告：蛋白质 {protein} 和 {protein2} 之间不存在路径。")
                continue

        print(f"蛋白质 {protein} 的最近 {n} 个蛋白质及其归一化距离、路径和置信度：")
        for protein2, distance, path, confidence in nearest_proteins_with_distance_and_path:
            print(f"蛋白质 {protein2}，归一化距离 {distance}, 路径为 {path}, 原始 combined_score 为 {confidence}")

        return nearest_proteins_with_distance_and_path

    def calculate_local_centralities(self, protein, k=3):
        """
        计算给定蛋白质附近的 k 层蛋白质的中心性。
        :param protein: 目标蛋白质
        :param k: 限制范围为蛋白质周围的 k 层，默认为 3
        :return: 返回一个包含蛋白质及其中心性值的字典
        """
        local_graph = self.get_local_subgraph(protein, k=k)
        if local_graph is None:
            return None

        degree_centrality = nx.degree_centrality(local_graph)
        closeness_centrality = nx.closeness_centrality(local_graph)
        betweenness_centrality = nx.betweenness_centrality(local_graph)

        centrality_results = {
            "protein": list(local_graph.nodes()),
            "degree_centrality": [degree_centrality[node] for node in local_graph.nodes()],
            "closeness_centrality": [closeness_centrality[node] for node in local_graph.nodes()],
            "betweenness_centrality": [betweenness_centrality[node] for node in local_graph.nodes()]
        }

        centrality_df = pd.DataFrame(centrality_results)
        return centrality_df
